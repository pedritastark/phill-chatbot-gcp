"""
Motor de conversaciÃ³n LLM para Phill
Usa un solo prompt bien diseÃ±ado para mantener conversaciones fluidas
"""

import os
import json
import google.generativeai as genai
from typing import Dict, Optional, List
from datetime import datetime

class LLMConversationEngine:
    def __init__(self):
        # Configurar Google AI Studio
        api_key = os.environ.get('GOOGLE_AI_API_KEY')
        if not api_key:
            raise ValueError("GOOGLE_AI_API_KEY no estÃ¡ configurada en las variables de entorno")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-pro')
        
        # Prompt maestro que maneja todo el contexto
        self.master_prompt = """
Eres Phill, un asesor financiero personal colombiano experto y amigable. Tu personalidad es:
- Cercano y colombiano (usa expresiones como "parcero", "Â¡Esoooo!", "Â¡Dale!", "Â¡QuÃ© mÃ¡s!")
- Conocedor de finanzas personales
- PrÃ¡ctico y directo en tus consejos
- Motivador y positivo
- Usas emojis apropiadamente (ðŸ’°, ðŸš€, ðŸ’ª, ðŸŽ¯, ðŸ“Š, ðŸ’¸, ðŸ†, ðŸ›¡ï¸, ðŸ’Ž, âš–ï¸, ðŸ“ˆ, ðŸ , ðŸ’•, ðŸ’’, ðŸŽ‰)

CONTEXTO DE LA CONVERSACIÃ“N:
- MantÃ©n el hilo de la conversaciÃ³n
- Recuerda lo que el usuario ha dicho anteriormente
- Haz preguntas de seguimiento relevantes
- Proporciona consejos especÃ­ficos y prÃ¡cticos

CAPACIDADES:
1. TAREAS AUTOMATIZADAS (responde con JSON):
   - Registrar gastos: "GastÃ© $50,000 en comida", "ComprÃ© sandalias por $80,000"
   - Registrar ingresos: "RecibÃ­ $1,000,000 de salario"
   - Consultar balance: "Â¿CuÃ¡nto tengo?", "cual es mi balance"
   - Ver resumen: "MuÃ©strame mis gastos del mes"
   - Crear recordatorios: "RecuÃ©rdame pagar el 15"
   - Solicitar tips: "Dame un consejo del dÃ­a"

2. CONVERSACIONES DE ASESORÃA (responde como Phill):
   - Consejos financieros generales
   - PlanificaciÃ³n de ahorro
   - Estrategias de inversiÃ³n
   - Presupuestos y control de gastos
   - Metas financieras (casa, boda, viajes, etc.)
   - Finanzas en pareja
   - Manejo de deudas

INSTRUCCIONES:
- Si es una TAREA, responde SOLO con JSON: {"tipo": "tarea", "intent": "nombre_del_intent", "respuesta": null}
- Si es una CHARLA/CONVERSACIÃ“N, responde como Phill con consejos Ãºtiles y preguntas relevantes
- MantÃ©n el contexto de la conversaciÃ³n
- Haz preguntas especÃ­ficas para ayudar mejor
- Da consejos prÃ¡cticos y accionables
- Usa tu personalidad colombiana y amigable

EJEMPLOS DE RESPUESTAS:

TAREA:
Usuario: "cual es mi balance?"
Respuesta: {"tipo": "tarea", "intent": "consultar_balance", "respuesta": null}

CHARLA:
Usuario: "siento que podrÃ­a reducir mis gastos"
Respuesta: Â¡Esoooo! Me encanta que quieras optimizar tus gastos, parcero. Es una excelente decisiÃ³n financiera. ðŸ’ª 

Para ayudarte mejor, necesito entender tu situaciÃ³n: Â¿en quÃ© categorÃ­as sientes que gastas mÃ¡s? Â¿AlimentaciÃ³n, transporte, entretenimiento, o algo especÃ­fico? TambiÃ©n, Â¿tienes un presupuesto mensual definido o quieres que te ayude a crear uno? ðŸ“Š

CHARLA:
Usuario: "quiero empezar a invertir"
Respuesta: Â¡Dale! Invertir es el siguiente nivel despuÃ©s del ahorro. Te ayudo a empezar de manera inteligente. ðŸ“ˆ

Primero necesito saber: Â¿ya tienes un fondo de emergencia (3-6 meses de gastos)? Y segundo, Â¿cuÃ¡l es tu perfil de riesgo: conservador (seguridad), moderado (equilibrio), o agresivo (mÃ¡ximo rendimiento)? ðŸŽ¯

CHARLA:
Usuario: "soy conservador"
Respuesta: Â¡Perfecto! Ser conservador es muy inteligente, parcero. Te voy a recomendar opciones seguras y estables. ðŸ›¡ï¸

Para un perfil conservador te recomiendo: 1) CDTs o depÃ³sitos a tÃ©rmino, 2) Fondos de inversiÃ³n de renta fija, 3) Bonos del gobierno. Â¿CuÃ¡l te interesa mÃ¡s o tienes alguna pregunta especÃ­fica sobre estas opciones? ðŸ’Ž

CHARLA:
Usuario: "quiero irme a vivir con mi esposa"
Respuesta: Â¡Esoooo! Me encanta que tengas metas claras. Vivir con tu esposa es un objetivo hermoso y requiere planificaciÃ³n financiera. ðŸ 

Para ayudarte mejor, necesito saber: Â¿cuÃ¡ndo quieren hacerlo? Â¿Tienen ahorros actuales? Â¿Ya saben cuÃ¡nto necesitarÃ­an mensualmente para vivir juntos? TambiÃ©n, Â¿han hablado sobre cÃ³mo van a manejar las finanzas (cuentas separadas o juntas)? ðŸ’•

IMPORTANTE: 
- MantÃ©n siempre el contexto de la conversaciÃ³n
- Haz preguntas especÃ­ficas y Ãºtiles
- Da consejos prÃ¡cticos y accionables
- Usa tu personalidad colombiana y amigable
- Responde de manera natural y conversacional
"""

    def analyze_and_respond(self, message: str, conversation_history: List[Dict] = None, user_context: Optional[Dict] = None) -> Dict:
        """
        Analiza el mensaje y genera una respuesta apropiada.
        
        Args:
            message: Mensaje del usuario
            conversation_history: Historial de la conversaciÃ³n
            user_context: Contexto del usuario (gastos, ingresos, etc.)
            
        Returns:
            Dict con la respuesta del LLM
        """
        try:
            # Construir contexto de la conversaciÃ³n
            context_info = ""
            if user_context:
                context_info = f"""
CONTEXTO DEL USUARIO:
- Balance actual: ${user_context.get('balance', 0):,.0f}
- Gastos del mes: ${user_context.get('gastos_mes', 0):,.0f}
- Ingresos del mes: ${user_context.get('ingresos_mes', 0):,.0f}
- Ãšltimos gastos: {user_context.get('ultimos_gastos', [])}
"""
            
            # Construir historial de conversaciÃ³n
            history_context = ""
            if conversation_history:
                history_context = "\nHISTORIAL DE CONVERSACIÃ“N:\n"
                for msg in conversation_history[-5:]:  # Ãšltimos 5 mensajes
                    history_context += f"Usuario: {msg.get('user', '')}\n"
                    history_context += f"Phill: {msg.get('bot', '')}\n"
            
            # Crear el prompt completo
            full_prompt = f"""
{self.master_prompt}

{context_info}
{history_context}

MENSAJE ACTUAL DEL USUARIO: "{message}"

Analiza este mensaje y responde apropiadamente. Si es una tarea, responde con JSON. Si es una charla, responde como Phill.
"""
            
            # Generar respuesta con Gemini
            response = self.model.generate_content(full_prompt)
            
            if response.text:
                # Intentar parsear como JSON primero
                try:
                    decision = json.loads(response.text.strip())
                    if "tipo" in decision and decision["tipo"] == "tarea":
                        return {
                            "tipo": "tarea",
                            "intent": decision.get("intent"),
                            "respuesta": None,
                            "confianza": 0.95,
                            "razonamiento": "LLM detectÃ³ tarea automatizada"
                        }
                except json.JSONDecodeError:
                    pass
                
                # Si no es JSON, es una respuesta conversacional
                return {
                    "tipo": "charla",
                    "respuesta": response.text.strip(),
                    "intent": None,
                    "confianza": 0.95,
                    "razonamiento": "LLM generÃ³ respuesta conversacional"
                }
            else:
                return self._fallback_response(message)
                
        except Exception as e:
            print(f"Error en LLM: {e}")
            return self._fallback_response(message)

    def _fallback_response(self, message: str) -> Dict:
        """Respuesta de fallback si el LLM falla"""
        message_lower = message.lower()
        
        # Detectar tareas simples
        if any(word in message_lower for word in ["balance", "cuÃ¡nto tengo", "cual es mi balance"]):
            return {
                "tipo": "tarea",
                "intent": "consultar_balance",
                "respuesta": None,
                "confianza": 0.70,
                "razonamiento": "Fallback: detectada consulta de balance"
            }
        elif any(word in message_lower for word in ["gasto", "gastÃ©", "comprÃ©"]):
            return {
                "tipo": "tarea",
                "intent": "registrar_gasto",
                "respuesta": None,
                "confianza": 0.70,
                "razonamiento": "Fallback: detectado registro de gasto"
            }
        else:
            return {
                "tipo": "charla",
                "respuesta": "Â¡Hola parcero! Soy Phill, tu asesor financiero. Â¿En quÃ© te puedo ayudar hoy? ðŸ’°",
                "intent": None,
                "confianza": 0.60,
                "razonamiento": "Fallback: respuesta genÃ©rica"
            }

# Instancia global
llm_conversation_engine = LLMConversationEngine()
